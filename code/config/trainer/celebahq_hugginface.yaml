defaults:
  - base_trainer
name: celeba_diffusion
platform: local
single_gpu: false
type: hugginface

# train: True #train from scratch
# eval: False #load ckpt.pt and evaluate FID and IS
test_session: False
qualitative_experiment: True
# Model ID hugginface
model_id: google/ddpm-ema-celebahq-256
log_root: /home/results 
random_seed: true
load_model_path: 

# Dataset
datapath: /home/datasets/CelebAMask-HQ/CelebA-HQ-img 
dataset: CELEBAHQ #help='dataset name')
exp_name_folder: fid
lsun_category: # one of ["bedroom","bridge","church_outdoor","classroom","conference_room","dining_room","kitchen","living_room","restaurant","tower",
corruptions_list: ["pixelate","gaussian_blur", "elastic_transform","shot_noise", "gaussian_noise", "frost", "jpeg_compression", 'masking_random_color'] #, 'masking_random_color','masking_vline_random_color'] #['gaussian_blur',"frost","speckle_noise","snow","motion_blur","pixelate","glass_blur",
                  #"elastic_transform",'impulse_noise', "shot_noise", "gaussian_noise",'masking_vline_random_color','masking_random_color'] 
                  #["frost", "speckle_noise",'impulse_noise', "shot_noise", "gaussian_noise","jpeg_compression","pixelate",
                  #"fog","gaussian_blur","elastic_transform", "motion_blur","glass_blur","brightness", "saturate",
                  #'snow', 'masking_vline_random_color', 'spatter', 'contrast', 'masking_random_color']
new_corruptions_list: ["perlin_noise", "checkerboard_cutout", "plasma_noise", "transverse_chromatic_abberation", "inverse_sparkles", ] # "checkerboard_cutout", "perlin_noise", plasma_noise]
                        #["lines", "blue_noise_sample", "caustic_refraction","pinch_and_twirl", "fish_eye", "water_drop", "ripple", 
                        #"perspective_no_bars","quadrilateral_no_bars", "scatter", "chromatic_abberation", "transverse_chromatic_abberation","circular_motion_blur",]
                        #["single_frequency_greyscale", "cocentric_sine_waves", "plasma_noise", "voronoi_noise",
                        #"caustic_noise", 'sparkles', "inverse_sparkles", "perlin_noise", "blue_noise", "brownish_noise",
                        #"bleach_bypass", "technicolor", "pseudocolor", "hue_shift", "color_dither",
                        #"checkerboard_cutout"] 
split: all
use_val: false
num_workers: 4 #help='workers of Dataloader')
corruption:  #help=corruption type base on Imagenet-C
corruption_severity:  #help='corruption severity level 1-5'
random_flip: False #help='Whether to use random flip in training')
img_size: 256 #help='image size')
use_lr_scheduler: true

# Training
model: "UNet2D"
reset_model: false
ddpm_timesteps: 1000
block_out_channels: [128, 128, 256, 256, 512, 512]
layers_per_block: 2
down_block_types : ["DownBlock2D",  # a regular ResNet downsampling block
                    "DownBlock2D", 
                    "DownBlock2D", 
                    "DownBlock2D", 
                    "AttnDownBlock2D",  # a ResNet downsampling block with spatial self-attention
                    "DownBlock2D",
                    ]
up_block_types: ["UpBlock2D",  # a regular ResNet upsampling block
                    "AttnUpBlock2D",  # a ResNet upsampling block with spatial self-attention
                    "UpBlock2D", 
                    "UpBlock2D", 
                    "UpBlock2D", 
                    "UpBlock2D"]

in_channels: 3
out_channels: 3
learning_rate: 1e-4
total_steps: 1000000000
gradient_accumulation_steps: 4
training_batch_size: 16
eval_batch_size: 16
dropout: 0.1
clip_grad_norm: 1.0
ema_decay: 0.95
lr_warmup_steps: 10000
mixed_precision: 'no' #['no', 'fp8', 'fp16', 'bf16']
ema_model: false

# Inference
run_sdedit: false
run_all_epsilon: false
use_std_schedule: false
number_of_image: 1000
number_of_sample: 1
image_number: 
batch_size: 1 #help='batch size'
annealing: 4
annealing_cst: 0.8
normalize: false 
normalize_mean: false
number_of_stds: 1.7
min_epsilon: 1e-5
max_epsilon: 2e-3
number_of_epsilons: 3
dynamic_thresholding_langevin: true
dynamic_thresholding_ddim: true
dynamic_threshol_ratio: 0.98
dynamic_threshold_max: 1.3
number_of_latents_corrected: 1
min_latent_space_update: 101
clip_input_encoding: true
clip_input_decoding: false
clip_inputs_langevin: false
stop_clipping_at: 0
start_from_latent: true
ode_range: [100, 500, 499]
sde_range: [399,400,500]
number_of_timesteps: 500
# Logging & Sampling
number_of_steps: 1000
logdir: ${trainer.log_root}/logs/CelebaHQ #help='log directory')
output_dir: ${trainer.load_model_path}
wandb_entity:  #help='wandb id to use')
ml_exp_name: RCP_${trainer.dataset}_${trainer.lsun_category}_folder_${trainer.exp_name_folder} #help = 'name of the experience on wandb')
base_dir: /home/CODE/
